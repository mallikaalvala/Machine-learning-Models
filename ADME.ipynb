# importing useful libraries
import pandas as pd
import numpy as np
import seaborn as snp
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error,mean_absolute_percentage_error

# "importing csv file of data consists of ADME propertoes calulated from any of the tools"
df=pd.read_csv("data.csv")

# Checking the data first few rows,columns
df.head()
df.info()
df.columns

# defining the dependent and indepnedentvariables
X=df[['LOGP']]
Y=df['CNS_permeability']

# splitting the data into training and test in 80:20 ratio
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)

# calling Linear Regression and fitting data
lr=LinearRegression()
lr.fit(X_train,Y_train);

# predcition of dependent varibale (Y)of training,test data based on independent variable(X)
Y_train_pred= lr.predict(X_train)
Y_test_pred=lr.predict(X_test)

#Visualising the actual and predicted values of training set as dataframe
pd.DataFrame({'Actual Train': Y_train, 'Predicted Train': np.round(Y_train_pred, 2)}).sample(5, random_state = 0)  # Training data

#Visualising the actual and predicted values of test set as dataframe
pd.DataFrame({'Actual test': Y_test, 'Predicted test': np.round(Y_test_pred, 2)}).sample(5, random_state = 0)  # Training data

# defining evaluation metrics
def regression_metrics(Y_train, Y_train_pred, Y_test, Y_test_pred):
    def compute_metrics(Y, Y_pred):
        # Compute evaluation metrics
        mse = mean_squared_error(Y, Y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(Y, Y_pred)
        mape = mean_absolute_percentage_error(Y, Y_pred) * 100
        r2 = r2_score(Y, Y_pred)

        # Compute statistics for comparison
        var = Y.var()  # Compares to the MSE
        std = Y.std()  # Compares to the RMSE
        mean_val = Y.mean()  # Acts as the 'typical value' when comparing to the MAE

        return mse, var, rmse, std, mae, mean_val, mape, r2

    metrics_train = compute_metrics(Y_train, Y_train_pred)
    metrics_test = compute_metrics(Y_test, Y_test_pred)

    return pd.DataFrame({'Dataset': ['Training', 'Testing'], 'MSE': [metrics_train[0], metrics_test[0]], 'Var': [metrics_train[1], metrics_test[1]],
                         'RMSE': [metrics_train[2], metrics_test[2]], 'Std Dev': [metrics_train[3], metrics_test[3]],
                         'MAE': [metrics_train[4], metrics_test[4]], 'Mean': [metrics_train[5], metrics_test[5]],'MAPE': [metrics_train[6], metrics_test[6]],
                         'RÂ²': [metrics_train[7], metrics_test[7]]}).set_index('Dataset')
#caluculating metrics
df_metrics = regression_metrics(Y_train, Y_train_pred, Y_test, Y_test_pred).round(2)
df_metrics

